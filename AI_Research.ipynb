{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# GPT-2 QLoRA + SEAL (Colab)\n",
        "\n",
        "This notebook sets up the environment on Google Colab, installs dependencies, clones the repository, and walks through:\n",
        "- Training GPT-2 Small with QLoRA (LoRA on 4-bit)\n",
        "- Evaluating perplexity\n",
        "- Running SEAL-style adaptation\n",
        "\n",
        "Use Runtime → Change runtime type → GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu_check"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability and basic environment\n",
        "import torch\n",
        "print('Torch:', torch.__version__)\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "!nvidia-smi || true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Install libraries (keep Colab's PyTorch)\n",
        "!pip -q install -U \"transformers>=4.40\" \"datasets>=2.15\" \"peft>=0.8.0\" \"accelerate>=0.27.0\" \"bitsandbytes>=0.44.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# Clone this repository and change directory\n",
        "import os\n",
        "if not os.path.exists('/content/Ai-Research'):\n",
        "    !git clone https://github.com/Hussain0327/Ai-Research.git /content/Ai-Research\n",
        "%cd /content/Ai-Research\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optional_drive"
      },
      "source": [
        "## Optional: Mount Google Drive\n",
        "Uncomment below to save checkpoints/results to Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# Example: use a Drive path\n",
        "# OUTPUT_DIR = '/content/drive/MyDrive/ai_research/checkpoints/gpt2_qlora_demo'\n",
        "# !mkdir -p $OUTPUT_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train_title"
      },
      "source": [
        "## Train QLoRA on GPT-2 (TXT sample)\n",
        "Small smoke test on the bundled text sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4da11bee",
      "metadata": {
        "id": "train_txt"
      },
      "outputs": [],
      "source": [
        "!python -m src.gpt2_qlora.train \\\n",
        "  --model_name gpt2 \\\n",
        "  --train_file data/sample/train.txt \\\n",
        "  --output_dir checkpoints/gpt2_qlora_demo \\\n",
        "  --lora_r 8 --lora_alpha 16 --lora_dropout 0.05 \\\n",
        "  --block_size 128 --batch_size 2 --epochs 1 --lr 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23a13eb4",
      "metadata": {
        "id": "eval_title"
      },
      "source": [
        "## Evaluate perplexity (TXT sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc75f1b7",
      "metadata": {
        "id": "eval_txt"
      },
      "outputs": [],
      "source": [
        "!python -m src.gpt2_qlora.eval \\\n",
        "  --model_name gpt2 \\\n",
        "  --adapter_dir checkpoints/gpt2_qlora_demo \\\n",
        "  --eval_file data/sample/train.txt \\\n",
        "  --block_size 128 --max_batches 50"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "643632a1",
      "metadata": {
        "id": "train_jsonl_title"
      },
      "source": [
        "## Train QLoRA on JSONL (repo `text.JSONL`)\n",
        "Uses the `text` field from the provided JSONL file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69aeed4d",
      "metadata": {
        "id": "train_jsonl"
      },
      "outputs": [],
      "source": [
        "!python -m src.gpt2_qlora.train \\\n",
        "  --model_name gpt2 \\\n",
        "  --train_file text.JSONL \\\n",
        "  --data_format jsonl --text_key text \\\n",
        "  --output_dir checkpoints/gpt2_qlora_jsonl \\\n",
        "  --lora_r 8 --block_size 128 --epochs 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "238017bd",
      "metadata": {
        "id": "seal_title"
      },
      "source": [
        "## SEAL-style adaptation (LoRA on GPT-2)\n",
        "Runs short inner-loop updates and logs metrics to JSONL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2667897b",
      "metadata": {
        "id": "seal_run"
      },
      "outputs": [],
      "source": [
        "!python -m src.seal.hf_seal \\\n",
        "  --model_name gpt2 \\\n",
        "  --baseline_adapter checkpoints/gpt2_qlora_demo \\\n",
        "  --save_dir checkpoints/gpt2_seal/adapt \\\n",
        "  --results results/gpt2_seal/adapt.jsonl \\\n",
        "  --inner_steps 1 3 10 \\\n",
        "  --lora_rank 4 8 \\\n",
        "  --train_file data/sample/train.txt \\\n",
        "  --val_file data/sample/train.txt \\\n",
        "  --block_size 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view_logs"
      },
      "source": [
        "## View adaptation logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tail_logs"
      },
      "outputs": [],
      "source": [
        "!tail -n 50 results/gpt2_seal/adapt.jsonl || echo 'No logs yet'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "accelerator": "GPU",
      "name": "AI_Research.ipynb"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
